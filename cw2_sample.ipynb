{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coursework Assignment 2: Measuring Sentence Similarity\n",
    "The purpose of this file is to help you develop your model. You **DON'T** need to submit this file. In the end, you should submit\n",
    "* A report, summarising all your findings and analyses.\n",
    "* For task 1 (MLP-based model), submit two files: **test_mlp.ipynb** which includes the impelementation, and **best_mlp.state_dict**, which is the saved MLP weights.\n",
    "* For task 2 (CNN- or RNN-based model), submit two files: **test_cnn.ipynb** (if you developed a RNN model, change cnn to rnn) which includes the impelementation, and **best_cnn.state_dict**, which is the saved CNN/RNN weights.\n",
    "* For task 3 (additional models), similarly, submit the implementation as well as the saved weights.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Sent1</th>\n",
       "      <th>Sent2</th>\n",
       "      <th>SimScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>U.S., EU Widen Sanctions On Russia</td>\n",
       "      <td>U.S., EU Boost Sanctions On Russia</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The lawyers advised the judges .</td>\n",
       "      <td>The lawyers advised the judges behind the acto...</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Man kills 4 in Calif. before police shoot him ...</td>\n",
       "      <td>Police: Gunman killed 6 in California shootings</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Someone is playing a piano.</td>\n",
       "      <td>A man is playing a guitar.</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>In an E-mail statement to the Knoxville News S...</td>\n",
       "      <td>I am not giving any consideration to resignati...</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11493</th>\n",
       "      <td>11493</td>\n",
       "      <td>A man is playing piano.</td>\n",
       "      <td>A man is laying on the ground.</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11494</th>\n",
       "      <td>11494</td>\n",
       "      <td>The doctors resigned , or the secretaries supp...</td>\n",
       "      <td>The doctors resigned .</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11495</th>\n",
       "      <td>11495</td>\n",
       "      <td>The artist contacted the banker .</td>\n",
       "      <td>The banker contacted the artist by the student .</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11496</th>\n",
       "      <td>11496</td>\n",
       "      <td>While the professors arrived , the student wai...</td>\n",
       "      <td>The professors arrived .</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11497</th>\n",
       "      <td>11497</td>\n",
       "      <td>The banker avoided the author .</td>\n",
       "      <td>The lawyer and the banker avoided the author .</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11498 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                              Sent1  \\\n",
       "0               0                 U.S., EU Widen Sanctions On Russia   \n",
       "1               1                   The lawyers advised the judges .   \n",
       "2               2  Man kills 4 in Calif. before police shoot him ...   \n",
       "3               3                        Someone is playing a piano.   \n",
       "4               4  In an E-mail statement to the Knoxville News S...   \n",
       "...           ...                                                ...   \n",
       "11493       11493                            A man is playing piano.   \n",
       "11494       11494  The doctors resigned , or the secretaries supp...   \n",
       "11495       11495                  The artist contacted the banker .   \n",
       "11496       11496  While the professors arrived , the student wai...   \n",
       "11497       11497                    The banker avoided the author .   \n",
       "\n",
       "                                                   Sent2  SimScore  \n",
       "0                     U.S., EU Boost Sanctions On Russia      1.00  \n",
       "1      The lawyers advised the judges behind the acto...      0.79  \n",
       "2        Police: Gunman killed 6 in California shootings      0.40  \n",
       "3                             A man is playing a guitar.      0.24  \n",
       "4      I am not giving any consideration to resignati...      0.80  \n",
       "...                                                  ...       ...  \n",
       "11493                     A man is laying on the ground.      0.15  \n",
       "11494                             The doctors resigned .      0.50  \n",
       "11495   The banker contacted the artist by the student .      0.29  \n",
       "11496                           The professors arrived .      0.61  \n",
       "11497     The lawyer and the banker avoided the author .      0.73  \n",
       "\n",
       "[11498 rows x 4 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data\n",
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv('cw2_train.csv')\n",
    "dev_data = pd.read_csv('cw2_dev.csv')\n",
    "\n",
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pre-Trained Embeddings\n",
    "In the sample code below, the Glove pre-trained embedding is used. Feel free to use other embeddings if you find it appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pre-trained glove embeddings\n",
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "import numpy as np\n",
    "\n",
    "word_vec_dim = 300\n",
    "# specify the loaction of the downloaded glove file\n",
    "path_of_downloaded_files = \"/Users/yg211/Embeddings/Glove/glove.6B.{}d.txt\".format(word_vec_dim)\n",
    "glove_file = datapath(path_of_downloaded_files)\n",
    "word2vec_glove_file = get_tmpfile(\"glove.6B.300d.txt\")\n",
    "glove2word2vec(glove_file, word2vec_glove_file)\n",
    "word_vectors = KeyedVectors.load_word2vec_format(word2vec_glove_file)\n",
    "\n",
    "oov_vec = np.random.rand(word_vec_dim)\n",
    "\n",
    "def get_sent_word_vecs(word_vectors, sent_words):\n",
    "    vecs = []\n",
    "    for ww in sent_words:\n",
    "        if ww in word_vectors:\n",
    "            vecs.append(word_vectors[ww])\n",
    "        else:\n",
    "            vecs.append(oov_vec)\n",
    "    return np.array(vecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Sentence Encoder\n",
    "Below, a simple model to create vector representations for sentences is provided. It first computes the average of the words embeddings, and then passes the average embedding to a fully-connected layer and applies a non-linear activation function to generate the final vector. You should develop more advanced models!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the baseline model\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class BaselineModel(nn.Module):\n",
    "    def __init__(self, embd_dim):\n",
    "        super(BaselineModel, self).__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fully_connected_layer = nn.Linear(embd_dim, embd_dim)\n",
    "        \n",
    "    def forward(self, sent1_vecs, sent2_vecs):\n",
    "        avg_embd1 = torch.mean(torch.FloatTensor(sent1_vecs), dim=0).unsqueeze(0)\n",
    "        avg_embd2 = torch.mean(torch.FloatTensor(sent2_vecs), dim=0).unsqueeze(0)\n",
    "        sent1_repr = self.relu(self.fully_connected_layer(avg_embd1))\n",
    "        sent2_repr = self.relu(self.fully_connected_layer(avg_embd2))\n",
    "        \n",
    "        return sent1_repr, sent2_repr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Pipeline\n",
    "The function *train_model* below provides a general pipeline for training the sentence encoder model. You could re-use it for training the model you have developed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def train_model(train_data, n_epochs, lr, optimizer, loss_fnc, model):\n",
    "    cos_sim = nn.CosineSimilarity()\n",
    "    for epoch_i in tqdm(range(n_epochs)):\n",
    "        ep_loss = []\n",
    "        cnt = 0\n",
    "        for i, entry in tqdm(train_data.sample(frac=1).iterrows()):\n",
    "            cnt += 1\n",
    "            sent1 = entry['Sent1']\n",
    "            sent2 = entry['Sent2']\n",
    "            sent1_embds = get_sent_word_vecs(word_vectors, sent1.split())\n",
    "            sent2_embds = get_sent_word_vecs(word_vectors, sent2.split())\n",
    "\n",
    "            # Step 1: Clear the gradients \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Step 2: Compute the forward pass of the model\n",
    "            sent1_repr, sent2_repr = model(sent1_embds, sent2_embds)\n",
    "            pred_sim = cos_sim(sent1_repr, sent2_repr)\n",
    "            true_sim = torch.FloatTensor([entry['SimScore']])\n",
    "\n",
    "            # Step 3: Compute the loss value that we wish to optimize\n",
    "            loss = loss_fnc(pred_sim, true_sim)\n",
    "            ep_loss.append(loss.detach())\n",
    "\n",
    "            # Step 4: Propagate the loss signal backward\n",
    "            loss.backward()\n",
    "\n",
    "            # Step 5: Trigger the optimizer to perform one update\n",
    "            optimizer.step()\n",
    "\n",
    "            if  cnt%1000 == 0:\n",
    "                print('epoch {}, avg loss until step {}: {}'.format(epoch_i, cnt, np.mean(ep_loss)))\n",
    "\n",
    "        print('\\n======epoch {} loss======'.format(epoch_i),np.mean(ep_loss))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Provide Hyper-Parameters and Start the Training\n",
    "The hyper-parameters and optimizers provided below are just some examples. You should use appropriate strategy to find the hyper-parameters that you want to use!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0c9bc438b5c4abca4bc0c3088064d4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de61026a52a14f2c92694c52a0b57153",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, avg loss until step 1000: 0.14674831926822662\n",
      "epoch 0, avg loss until step 2000: 0.14022010564804077\n",
      "epoch 0, avg loss until step 3000: 0.13518832623958588\n",
      "epoch 0, avg loss until step 4000: 0.13421045243740082\n",
      "epoch 0, avg loss until step 5000: 0.13155771791934967\n",
      "epoch 0, avg loss until step 6000: 0.1290311962366104\n",
      "epoch 0, avg loss until step 7000: 0.1275046318769455\n",
      "epoch 0, avg loss until step 8000: 0.12645980715751648\n",
      "epoch 0, avg loss until step 9000: 0.12443555891513824\n",
      "epoch 0, avg loss until step 10000: 0.12312386184930801\n",
      "epoch 0, avg loss until step 11000: 0.12149453908205032\n",
      "\n",
      "======epoch 0 loss====== 0.120683275\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08d509a392974d97ab5a5c7344131136",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, avg loss until step 1000: 0.10665220767259598\n",
      "epoch 1, avg loss until step 2000: 0.10343792289495468\n",
      "epoch 1, avg loss until step 3000: 0.10377679765224457\n",
      "epoch 1, avg loss until step 4000: 0.10182622075080872\n",
      "epoch 1, avg loss until step 5000: 0.1004737988114357\n",
      "epoch 1, avg loss until step 6000: 0.09962590783834457\n",
      "epoch 1, avg loss until step 7000: 0.09987521171569824\n",
      "epoch 1, avg loss until step 8000: 0.09923209249973297\n",
      "epoch 1, avg loss until step 9000: 0.09845659881830215\n",
      "epoch 1, avg loss until step 10000: 0.09825022518634796\n",
      "epoch 1, avg loss until step 11000: 0.09759816527366638\n",
      "\n",
      "======epoch 1 loss====== 0.09707777\n"
     ]
    }
   ],
   "source": [
    "model = BaselineModel(word_vec_dim)\n",
    "loss_fnc = nn.MSELoss()\n",
    "\n",
    "# hyper parameters\n",
    "n_epochs = 2 \n",
    "lr = 1e-3 \n",
    "\n",
    "# init optimizer and scheduler (lr adjustor)\n",
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=lr) \n",
    "\n",
    "train_model(train_data, n_epochs, lr, optimizer, loss_fnc, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate The Trained Model\n",
    "The function *evaluate_trained_model* defined below tests the performance of a trained model on the dev_set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def evaluate_trained_model(trained_model, dev_data):\n",
    "    pred_scores = []\n",
    "    true_scores = []\n",
    "    cos_sim = nn.CosineSimilarity()\n",
    "    with torch.no_grad(): # let pytorch know that no gradient should be computed\n",
    "        model.eval()\n",
    "        for i, entry in tqdm(dev_data.iterrows()):\n",
    "            sent1 = entry['Sent1']\n",
    "            sent2 = entry['Sent2']\n",
    "            gold_score = entry['SimScore']\n",
    "            sent1_embds = get_sent_word_vecs(word_vectors, sent1.split())\n",
    "            sent2_embds = get_sent_word_vecs(word_vectors, sent2.split())\n",
    "            sent1_repr, sent2_repr = trained_model(sent1_embds, sent2_embds)\n",
    "            pred_sim = cos_sim(sent1_repr, sent2_repr)\n",
    "        \n",
    "            pred_scores.append(pred_sim)\n",
    "            true_scores.append(gold_score)\n",
    "\n",
    "    assert len(true_scores) == len(pred_scores)\n",
    "    squared_errors = [np.square(ts-ps) for (ts, ps) in zip(true_scores, pred_scores)]\n",
    "    print('MSE of the method on the dev set:', np.mean(squared_errors))\n",
    "\n",
    "    # check the distribution (histo gram) of the squared errors\n",
    "    plt.hist(squared_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "351ffdf3a3dd4361b487e17b00ccce2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of the method on the dev set: 0.09156774\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_trained_model(model, dev_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save trained model\n",
    "The code below illustrates how to save the trained model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "info_to_save = {\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'oov_vec': oov_vec\n",
    "}\n",
    "\n",
    "with open('sample_model.state_dict', 'wb') as ff:\n",
    "    pickle.dump(info_to_save, ff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_nlp",
   "language": "python",
   "name": "venv_nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
