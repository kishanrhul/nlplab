{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Text Classification\n",
    "In this notebook, you will first see a simple Naive Bayes (NB) classifier, which is trained on a tiny toy corpus to classify texts into categories of 'sports' and 'not sports'. Then you are asked to apply and adjust the NB classifier to perform sentiment analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# toy tiny corpus: sports and non-sports sentences\n",
    "sports = ['A great game', 'Very clean match','A clean but forgettable game']\n",
    "non_sports = ['The election was over','It was a close election']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build vocabulary\n",
    "all_words = []\n",
    "sport_words = []\n",
    "non_sport_words = []\n",
    "for sent in sports:\n",
    "    sport_words += [ww.lower() for ww in sent.split()]\n",
    "for sent in non_sports:\n",
    "    non_sport_words += [ww.lower() for ww in sent.split()]\n",
    "\n",
    "all_words = sport_words + non_sport_words\n",
    "vocab = list(set(all_words))\n",
    "\n",
    "print(all_words)\n",
    "print(len(vocab), vocab)\n",
    "\n",
    "print('sport token nums', len(sport_words))\n",
    "print('sport type nums', len(set(sport_words)))\n",
    "print('non-sport token nums', len(non_sport_words))\n",
    "print('non-sport type nums', len(set(non_sport_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the prior distribution\n",
    "prior_sport = len(sports)*1./(len(sports)+len(non_sports))\n",
    "prior_non_sport = len(non_sports)*1./(len(sports)+len(non_sports))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the word frequencies, which will be later used to compute likelihood\n",
    "from nltk import FreqDist\n",
    "sport_fd = FreqDist(sport_words)\n",
    "non_sport_fd = FreqDist(non_sport_words)\n",
    "\n",
    "print(sport_fd['close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NB classifier\n",
    "import numpy as np\n",
    "def predict_class(words):\n",
    "    sport_likelihood = []\n",
    "    non_likelihood = []\n",
    "    for ww in words:\n",
    "        sport_likelihood.append((sport_fd[ww]+1.)/(len(sport_words)+len(vocab)))\n",
    "        non_likelihood.append((non_sport_fd[ww]+1.)/(len(non_sport_words)+len(vocab)))\n",
    "    print(sport_likelihood)\n",
    "    print(non_likelihood)\n",
    "    s_loglhd = np.sum([np.log(l) for l in sport_likelihood])\n",
    "    n_loglhd = np.sum([np.log(l) for l in non_likelihood])\n",
    "    print(s_loglhd, n_loglhd)\n",
    "    sprob = np.log(prior_sport)+s_loglhd\n",
    "    nprob = np.log(prior_non_sport)+n_loglhd\n",
    "    if sprob > nprob: return 'sport'\n",
    "    else: return 'non_sport'\n",
    "    \n",
    "print(predict_class('a very interesting game'.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: NB-based Sentiment Analysis\n",
    "*Sentiment analysis* is probably the most commerical application of text classification. It takes a customer review and checks the overall sentiment of the review. Here we use the movie review corpus to train a NB-based sentiment analyzer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain the data\n",
    "from nltk.corpus import movie_reviews\n",
    "import random\n",
    "documents = [(list(movie_reviews.words(fileid)), category)\n",
    "             for category in movie_reviews.categories()\n",
    "             for fileid in movie_reviews.fileids(category)]\n",
    "random.shuffle(documents)\n",
    "\n",
    "print('document num', len(documents))\n",
    "print('labels:', set([dd[1] for dd in documents]))\n",
    "print(documents[0][0], documents[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into train, dev-test and test\n",
    "\n",
    "train_data = documents[:1200]\n",
    "dev_data = documents[1200:1600]\n",
    "test_data = documents[1600:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the prior probability of pos and neg (based on train_data)\n",
    "prior_pos = ...\n",
    "prior_neg = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build vocabulary based on train_data\n",
    "# you may investigate whether to remove stopwords and punctuations and \n",
    "# whether to apply lemmatization/stemming, and compare their performance on dev-test set \n",
    "\n",
    "vocab = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each class (pos and neg), maintain the frequency of each type, so as to compute likelihood\n",
    "from nltk import FreqDist\n",
    "pos_fd = FreqDist(pos_words)\n",
    "neg_fd = FreqDist(neg_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the class prediction function\n",
    "def predict_sentiment(input_text):\n",
    "    pass\n",
    "\n",
    "# evaluate your model's performance on the dev-test set\n",
    "dev_pred_labels = []\n",
    "dev_true_labels = [ll for (dd,ll) in dev_data]\n",
    "for tt,_ in dev_data:\n",
    "    dev_pred_labels.append(predict_sentiment(tt))\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "print('acc', accuracy_score(dev_true_labels, dev_pred_labels))\n",
    "print(precision_recall_fscore_support(dev_true_labels, dev_pred_labels, average=None, labels=['pos', 'neg']))\n",
    "\n",
    "# develop different models (with and without stopwords/punctuations/stemming/lemmatization),\n",
    "# and select the best model by its performance on the dev-test set;\n",
    "# the selected best model will be applied to test data in the next step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the performance of the best model on test set\n",
    "test_pred_labels = []\n",
    "test_true_labels = [ll for (dd,ll) in test_data]\n",
    "for tt,_ in test_data:\n",
    "    test_pred_labels.append(predict_sentiment(tt))\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "print('acc', accuracy_score(test_true_labels, test_pred_labels))\n",
    "print(precision_recall_fscore_support(test_true_labels, test_pred_labels, average=None, labels=['pos', 'neg']))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_nlp",
   "language": "python",
   "name": "venv_nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
