{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-gram Language Model\n",
    "In this exercise, we will build an n-gram language model based on the Shakespeare corpus, and generate some Shakespeare-style text using the language model. Going beyond that, you can use the same technique to build language models using other corpora. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Obtain the corpus. \n",
    "# NOTE: here corpus itself has performed the tokenization operation\n",
    "from nltk.corpus import shakespeare\n",
    "books = shakespeare.fileids()\n",
    "all_words = []\n",
    "for bk in books:\n",
    "    all_words += shakespeare.words(bk)\n",
    "all_words = [ww.lower() for ww in all_words]\n",
    "print(all_words[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: extract n-grams from all_words\n",
    "\n",
    "def extract_ngrams(word_list, n_value):\n",
    "    # INPUT: word_list, a list of tokens \n",
    "    # INPUT: n_value, the desirable n value\n",
    "    # Output: a list of n-grams\n",
    "    pass\n",
    "\n",
    "n_value = 2 # you can let it be 2 or 3 or 4 or ...\n",
    "all_ngrams_list = extract_ngrams(all_words, n_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: build the n-gram language model (LM)\n",
    "# the built n-gram LM should allow you to check the frequency n-grams conditioned on some n-1 grams\n",
    "# for example, suppose I have built a 3-gram LM; when I query model(('tragedy','of')), \n",
    "# it should return something like: \n",
    "# {'antony': 1, 'hamlet': 1, 'julius': 1, 'macbeth': 1, 'othello': 1, 'romeo': 1},\n",
    "# indicating that 'tragedy of antony' appears once in the corpus, \n",
    "# 'tragedy of hamlet' appears once, etc.\n",
    "# HINT: you may use the ConditionalFreqDict function from NLTK to build the LM\n",
    "\n",
    "def build_lm(all_ngrams_list, n_value):\n",
    "    pass\n",
    "\n",
    "lang_model = build_lm(all_ngrams_list, n_value)\n",
    "print(lang_model(('tragedy','of')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: generate text using the built LM\n",
    "\n",
    "def generate_text(lang_model, initial_words, wanted_text_length=100, word_selection_strategy='greedy'):\n",
    "    # this function allows you to provide the first n-1 word, and it will\n",
    "    # generate some text following your input words using the language model\n",
    "    # INPUT lang_model: the LM you have built\n",
    "    # INPUT initial_words: a list/tuple that includes the first few (n-1) words \n",
    "    # INPUT wanted_text_length: how many words you want the model to generate \n",
    "    # INPUT word_selection_strategy: how to select the next word from the LM (e.g. greedy, random, or following certain probability distributions)\n",
    "    # OUTPUT: a list of words the text-generator generates\n",
    "    pass\n",
    "\n",
    "print(' '.join(generate_text(lang_model,('the','tragedy'))))\n",
    "# you may expect the outcome be a piece of text like:\n",
    "# the tragedy of hamlet sits smiling to my mind did lose it . first musician no . mark antony speak to her wounds : then it was your enemy say so : but words are suited ! i partly feel thee . bid you alexas to mardian bring me word , menecrates , and but thou hast need . benvolio tut , dun ' s something tells me , heaven forgive him ! emilia she give that ? and do invite you to use . mine eyes . exit portia come hither arm ' d till i come : give me grace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra task 1: \n",
    "Try different n_value and see their influence on the quality of the generated text; you should see that with larger n_value, the generated text reads better.\n",
    "\n",
    "### Going beyond: \n",
    "Build LM on other corpora (e.g. Reuters, Brown) and generate text, check the different styles of generated text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_nlp",
   "language": "python",
   "name": "venv_nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
