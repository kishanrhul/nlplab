{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Syntactic Parsing with Spacy\n",
    "Spacy provides a full-stack syntactic analysis toolkit. In this exercise, we will first take a look at how to use Spacy to perform different syntactic analysis tasks, and then try to use the analysis results to answer some questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POS tagger\n",
    "doc = nlp('He went to South Africa for holiday.')\n",
    "print('word\\tPenn\\tUniversal')\n",
    "for ww in doc:\n",
    "    print('{}\\t{}\\t{}'.format(ww,ww.tag_,ww.pos_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get help information for pos tags\n",
    "import nltk\n",
    "print(nltk.help.upenn_tagset('NNP'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunking\n",
    "nlp = en_core_web_sm.load()\n",
    "doc = nlp('He went to South Africa on Christmas day.')\n",
    "for chunk in doc.noun_chunks:\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# named entity recognition (NER)\n",
    "nlp = en_core_web_sm.load()\n",
    "doc = nlp('He went to South Africa on Christmas day.')\n",
    "for i,ent in enumerate(doc.ents):\n",
    "    print('named entity {}: {}, label {}'.format(i,ent.text,ent.label_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization of NER results\n",
    "from spacy import displacy\n",
    "displacy.render(doc,style='ent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependency parsing \n",
    "doc = nlp('I shot an elephant in my pajamas')\n",
    "for token in doc:\n",
    "    print(token.text, token.dep_, token.head.text, token.head.pos_,\n",
    "            [child for child in token.children])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the dependency parsing result\n",
    "from spacy import displacy\n",
    "displacy.render(doc,style='dep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunks also includes dependency information\n",
    "doc = nlp('Amazon purchases Whole Foods for $13.4 billion.')\n",
    "for chunk in doc.noun_chunks:\n",
    "    print('{}|{}|{}|{}'.format(chunk.text, chunk.root.text, chunk.root.dep_,\n",
    "            chunk.root.head.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple application of chunking and dependency parsing\n",
    "def who_purchases_whom(doc):\n",
    "    for chunk in doc.noun_chunks:\n",
    "        if 'purchase' in chunk.root.head.text and 'subj' in chunk.root.dep_:\n",
    "            subj = chunk.text\n",
    "        elif 'purchase' in chunk.root.head.text and 'obj' in chunk.root.dep_:\n",
    "            obj = chunk.text\n",
    "    return subj, obj\n",
    "\n",
    "subj, obj = who_purchases_whom(doc)\n",
    "print('{} bought {}'.format(subj,obj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_nlp",
   "language": "python",
   "name": "venv_nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
